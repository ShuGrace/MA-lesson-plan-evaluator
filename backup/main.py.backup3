from fastapi import FastAPI, Depends, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from app.db.database import Database, init_database
from typing import List, Optional
from pydantic import BaseModel
import traceback
from contextlib import asynccontextmanager
from io import BytesIO
import json
import time
import asyncio
from functools import wraps

import logging

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("uvicorn")




# æ€§èƒ½ç›‘æŽ§è£…é¥°å™¨
def timing_decorator(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            end_time = time.time()
            print(f"â±ï¸ {func.__name__} executed in {end_time - start_time:.2f} seconds")
            return result
        except Exception as e:
            end_time = time.time()
            print(f"â±ï¸ {func.__name__} failed after {end_time - start_time:.2f} seconds: {e}")
            raise
    return wrapper

# åˆ†æ•°è¿›åº¦æ¡é¢œè‰²è¾…åŠ©å‡½æ•°
def score_color(score: Optional[int]) -> str:
    if score is None:
        return "grey"
    try:
        return "red" if score < 60 else "orange" if score < 80 else "green"
    except Exception:
        return "grey"

# æ–‡ä»¶å¤„ç†åº“
try:
    import docx
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("âš ï¸ python-docx not installed")

try:
    import PyPDF2
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    print("âš ï¸ PyPDF2 not installed")

from app.config import API_MODE
from app.services.llm_client import LLMClient

@asynccontextmanager
async def lifespan(app: FastAPI):
    try:
        init_database(reset=False)
        print("âœ… Database initialized successfully")
    except Exception as e:
        print(f"âš ï¸  Database initialization warning: {e}")
    yield
    print("ðŸ‘‹ Application shutdown")

app = FastAPI(title="Lesson Plan Evaluator API", lifespan=lifespan)

# ä¿®å¤CORSé…ç½® - å…³é”®ä¿®å¤ç‚¹
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­åº”è¯¥æŒ‡å®šå…·ä½“çš„å‰ç«¯URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],  # æ·»åŠ expose_headers
    max_age=3600,  # é¢„æ£€è¯·æ±‚ç¼“å­˜æ—¶é—´
)

# -------- Models --------
class EvaluationCreate(BaseModel):
    lesson_plan_text: str
    lesson_plan_title: Optional[str] = None
    grade_level: Optional[str] = None
    subject_area: Optional[str] = None

class EvaluationUpdate(BaseModel):
    place_based_score: Optional[int] = None
    cultural_score: Optional[int] = None
    overall_score: Optional[int] = None
    status: Optional[str] = None
    agent_responses: Optional[List[dict]] = None
    debate_transcript: Optional[dict] = None
    recommendations: Optional[List[str]] = None

class ImproveLessonRequest(BaseModel):
    original_lesson: str
    lesson_title: str
    grade_level: Optional[str] = None
    subject_area: Optional[str] = None
    recommendations: List[str]
    scores: dict

def get_db():
    db = Database()
    db.connect()
    try:
        yield db
    finally:
        db.close()

@app.get("/")
async def root():
    return {
        "message": "Lesson Plan Evaluator API",
        "mode": API_MODE,
        "database": "connected",
        "status": "operational",
        "features": {
            "file_upload": {
                "word": DOCX_AVAILABLE,
                "pdf": PDF_AVAILABLE
            }
        }
    }

# -------- Lesson Plan Template --------
LESSON_PLAN_TEMPLATE = """
**1. Learning Objectives**
1.1 Knowledge: {knowledge}
1.2 Skills: {skills}
1.3 Attitudes/Values: {values}

**2. Learner Analysis**
2.1 Student Background:
2.1.1 Prior knowledge or skills related to the topic: {prior_knowledge}
2.1.2 Possible interests or connections to the topic: {interests}
2.1.3 Anticipated challenges or difficulties: {challenges}
2.2 Learner Characteristics:
2.2.1 Learning styles: {learning_styles}
2.2.2 Special needs or accommodations: {accommodations}

**3. Key Points of Focus**
3.1 Teaching Focus (Key Concepts): {key_concepts}
3.2 Challenges (Potential Difficulties): {focus_challenges}

**4. Teaching Methods and Strategies**
4.1 Methods: {methods}
4.2 Strategies: {strategies}

**5. Preparation**
5.1 Teacher Preparation: {teacher_prep}
5.2 Student Preparation: {student_prep}

**6. Lesson Procedure**
| Stage | Details | Duration | Teaching Methods |
|-------|---------|----------|------------------|
| Introduction | {intro_details} | {intro_duration} | {intro_methods} |
| Main teaching | {main_details} | {main_duration} | {main_methods} |
| Activities | {activity_details} | {activity_duration} | {activity_methods} |
| Conclusion | {conclusion_details} | {conclusion_duration} | {conclusion_methods} |
| Extension | {extension_details} | {extension_duration} | {extension_methods} |

**7. Assessment**
7.1 Formative Assessment: {formative}
7.2 Summative Assessment: {summative}
7.3 Feedback Mechanisms: {feedback}

**8. Resources and Tools**
8.1 Materials Needed: {materials}
8.2 Technology and Tools: {tech_tools}

**Cultural Disclaimers and Acknowledgment of Limitations:**
This AI-generated lesson plan requires your review and adaptation before use. Please consult with local iwi and cultural advisors for MÄori content. AI systems lack cultural understanding and lived experienceâ€”critically evaluate all content for cultural appropriateness and te reo MÄori accuracy. You retain full responsibility for ensuring this lesson suits your teaching context and respects local protocols.
"""

def generate_lesson_plan_from_fields(fields: dict) -> str:
    return LESSON_PLAN_TEMPLATE.format(
        knowledge=fields.get("knowledge", ""),
        skills=fields.get("skills", ""),
        values=fields.get("values", ""),
        prior_knowledge=fields.get("prior_knowledge", ""),
        interests=fields.get("interests", ""),
        challenges=fields.get("challenges", ""),
        learning_styles=fields.get("learning_styles", ""),
        accommodations=fields.get("accommodations", ""),
        key_concepts=fields.get("key_concepts", ""),
        focus_challenges=fields.get("focus_challenges", ""),
        methods=fields.get("methods", ""),
        strategies=fields.get("strategies", ""),
        teacher_prep=fields.get("teacher_prep", ""),
        student_prep=fields.get("student_prep", ""),
        intro_details=fields.get("intro_details", ""),
        intro_duration=fields.get("intro_duration", ""),
        intro_methods=fields.get("intro_methods", ""),
        main_details=fields.get("main_details", ""),
        main_duration=fields.get("main_duration", ""),
        main_methods=fields.get("main_methods", ""),
        activity_details=fields.get("activity_details", ""),
        activity_duration=fields.get("activity_duration", ""),
        activity_methods=fields.get("activity_methods", ""),
        conclusion_details=fields.get("conclusion_details", ""),
        conclusion_duration=fields.get("conclusion_duration", ""),
        conclusion_methods=fields.get("conclusion_methods", ""),
        extension_details=fields.get("extension_details", ""),
        extension_duration=fields.get("extension_duration", ""),
        extension_methods=fields.get("extension_methods", ""),
        formative=fields.get("formative", ""),
        summative=fields.get("summative", ""),
        feedback=fields.get("feedback", ""),
        materials=fields.get("materials", ""),
        tech_tools=fields.get("tech_tools", "")
    )

llm_client = LLMClient()

@app.post("/api/extract-text")
async def extract_text_from_file(file: UploadFile = File(...)):
    """
    æ–‡ä»¶ä¸Šä¼ ç«¯ç‚¹ - å¢žå¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—
    """
    print(f"\n{'='*60}")
    print(f"ðŸ“ FILE UPLOAD REQUEST")
    print(f"{'='*60}")
    print(f"Filename: {file.filename}")
    print(f"Content-Type: {file.content_type}")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        file_size = len(content)
        print(f"File size: {file_size} bytes ({file_size/1024:.2f} KB)")
        
        if file_size == 0:
            raise HTTPException(status_code=400, detail="File is empty")
        
        text = ""
        title = ""
        
        # å¤„ç† Word æ–‡æ¡£
        if file.filename.lower().endswith('.docx'):
            if not DOCX_AVAILABLE:
                raise HTTPException(
                    status_code=501, 
                    detail="Word file support not installed. Please install: pip install python-docx"
                )
            
            print("ðŸ“„ Processing Word document...")
            try:
                doc = docx.Document(BytesIO(content))
                paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]
                text = '\n\n'.join(paragraphs)
                
                if paragraphs:
                    title = paragraphs[0][:100]
                
                print(f"âœ… Extracted {len(paragraphs)} paragraphs")
                print(f"âœ… Total characters: {len(text)}")
                
            except Exception as e:
                print(f"âŒ Word processing error: {str(e)}")
                print(traceback.format_exc())
                raise HTTPException(
                    status_code=500, 
                    detail=f"Failed to process Word document: {str(e)}"
                )
        
        # å¤„ç† PDF æ–‡æ¡£
        elif file.filename.lower().endswith('.pdf'):
            if not PDF_AVAILABLE:
                raise HTTPException(
                    status_code=501, 
                    detail="PDF support not installed. Please install: pip install PyPDF2"
                )
            
            print("ðŸ“„ Processing PDF document...")
            try:
                pdf_reader = PyPDF2.PdfReader(BytesIO(content))
                num_pages = len(pdf_reader.pages)
                print(f"ðŸ“‘ PDF has {num_pages} pages")
                
                pages_text = []
                for i, page in enumerate(pdf_reader.pages):
                    print(f"Processing page {i+1}/{num_pages}...")
                    page_text = page.extract_text()
                    if page_text and page_text.strip():
                        pages_text.append(page_text)
                
                text = '\n\n'.join(pages_text)
                title = file.filename.replace('.pdf', '')
                
                if text and len(text) > 0:
                    first_line = text.split('\n')[0][:100]
                    if first_line:
                        title = first_line
                
                print(f"âœ… Extracted {len(pages_text)} pages")
                print(f"âœ… Total characters: {len(text)}")
                
            except Exception as e:
                print(f"âŒ PDF processing error: {str(e)}")
                print(traceback.format_exc())
                raise HTTPException(
                    status_code=500, 
                    detail=f"Failed to process PDF: {str(e)}"
                )
        
        # ä¸æ”¯æŒçš„æ ¼å¼
        elif file.filename.lower().endswith('.doc'):
            raise HTTPException(
                status_code=400, 
                detail="Old .doc format not supported. Please convert to .docx"
            )
        else:
            raise HTTPException(
                status_code=400, 
                detail=f"Unsupported file format. Only .docx and .pdf are supported. Got: {file.filename}"
            )
        
        # éªŒè¯æå–çš„æ–‡æœ¬
        if not text or not text.strip():
            raise HTTPException(
                status_code=400, 
                detail="No text content could be extracted from the file"
            )
        
        word_count = len(text.split())
        print(f"\nâœ… FILE PROCESSING SUCCESSFUL")
        print(f"Title: {title}")
        print(f"Characters: {len(text)}")
        print(f"Words: {word_count}")
        print(f"{'='*60}\n")
        
        return {
            "status": "success",
            "text": text,
            "metadata": {
                "title": title,
                "filename": file.filename,
                "length": len(text),
                "word_count": word_count
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"\nâŒ UNEXPECTED ERROR")
        print(f"Error: {str(e)}")
        print(traceback.format_exc())
        print(f"{'='*60}\n")
        raise HTTPException(
            status_code=500, 
            detail=f"File processing failed: {str(e)}"
        )


class ConvertToWordRequest(BaseModel):
    content: str
    filename: str

@app.post("/api/convert-to-word")
async def convert_to_word(request: ConvertToWordRequest):
    try:
        if not DOCX_AVAILABLE:
            raise HTTPException(status_code=501, detail="Word conversion not available. Install python-docx.")
        from fastapi.responses import StreamingResponse
        doc = docx.Document()
        doc.add_heading('Improved Lesson Plan', 0)
        lines = request.content.split('\n')
        current_table = None
        in_table = False
        skip_next = False
        for i, line in enumerate(lines):
            if skip_next:
                skip_next = False
                continue
            line = line.strip()
            if not line:
                in_table = False
                current_table = None
                continue
            if '|' in line and '---' in line:
                skip_next = False
                continue
            if line.count('|') >= 3 and not line.startswith('[') and '---' not in line:
                cells = [cell.strip() for cell in line.split('|')[1:-1]]
                is_real_table = False
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if '|' in next_line and '---' in next_line:
                        is_real_table = True
                        skip_next = True
                if is_real_table and not in_table:
                    in_table = True
                    current_table = doc.add_table(rows=1, cols=len(cells))
                    current_table.style = 'Light Grid Accent 1'
                    hdr_cells = current_table.rows[0].cells
                    for j, header in enumerate(cells):
                        hdr_cells[j].text = header
                        for paragraph in hdr_cells[j].paragraphs:
                            for run in paragraph.runs:
                                run.font.bold = True
                elif in_table and current_table:
                    row_cells = current_table.add_row().cells
                    for j, cell_text in enumerate(cells):
                        if j < len(row_cells):
                            row_cells[j].text = cell_text
                else:
                    in_table = False
                    doc.add_paragraph(line)
            else:
                in_table = False
                current_table = None
                if line.startswith('# '):
                    doc.add_heading(line[2:], level=1)
                elif line.startswith('## '):
                    doc.add_heading(line[3:], level=2)
                elif line.startswith('### '):
                    doc.add_heading(line[4:], level=3)
                elif line.startswith('**') and line.endswith('**'):
                    p = doc.add_paragraph()
                    p.add_run(line.strip('**')).bold = True
                elif line.startswith('- ') or line.startswith('* '):
                    doc.add_paragraph(line[2:], style='List Bullet')
                elif line.startswith(tuple(str(i) + '.' for i in range(10))):
                    doc.add_paragraph(line, style='List Number')
                else:
                    doc.add_paragraph(line)
        file_stream = BytesIO()
        doc.save(file_stream)
        file_stream.seek(0)
        return StreamingResponse(
            file_stream,
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            headers={"Content-Disposition": f"attachment; filename={request.filename}"}
        )
    except Exception as e:
        print(f"Error converting to Word: {str(e)}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Word conversion failed: {str(e)}")


@app.post("/api/evaluations", response_model=dict)
async def create_evaluation_record(evaluation: EvaluationCreate, db: Database = Depends(get_db)):
    try:
        eval_id = db.create_evaluation(
            lesson_plan_text=evaluation.lesson_plan_text,
            lesson_plan_title=evaluation.lesson_plan_title,
            grade_level=evaluation.grade_level,
            subject_area=evaluation.subject_area,
            api_mode=API_MODE
        )
        return {"status": "success", "evaluation_id": eval_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create evaluation: {str(e)}")


@app.get("/api/evaluations")
async def get_all_evaluations(limit: int = 50, status: Optional[str] = None, db: Database = Depends(get_db)):
    try:
        if status:
            evals = db.get_evaluations_by_status(status)
        else:
            evals = db.get_all_evaluations(limit=limit)
        return {
            "status": "success",
            "evaluations": evals,
            "count": len(evals)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve evaluations: {str(e)}")


@app.get("/api/evaluations/{evaluation_id}")
async def get_evaluation_by_id(evaluation_id: int, db: Database = Depends(get_db)):
    evaluation = db.get_evaluation(evaluation_id)
    if not evaluation:
        raise HTTPException(status_code=404, detail="Evaluation not found")
    return {
        "status": "success",
        "evaluation": evaluation
    }


@app.put("/api/evaluations/{evaluation_id}", response_model=dict)
async def update_evaluation(evaluation_id: int, update_data: EvaluationUpdate, db: Database = Depends(get_db)):
    evaluation = db.get_evaluation(evaluation_id)
    if not evaluation:
        raise HTTPException(status_code=404, detail="Evaluation not found")
    if all([update_data.place_based_score, update_data.cultural_score, update_data.overall_score]):
        db.update_evaluation_scores(
            eval_id=evaluation_id,
            place_based_score=update_data.place_based_score,
            cultural_score=update_data.cultural_score,
            overall_score=update_data.overall_score
        )
    if update_data.agent_responses or update_data.debate_transcript or update_data.recommendations:
        db.update_evaluation_results(
            eval_id=evaluation_id,
            agent_responses=update_data.agent_responses or [],
            debate_transcript=update_data.debate_transcript or {},
            recommendations=update_data.recommendations or [],
            status=update_data.status or "completed"
        )
    if update_data.status and not any([update_data.agent_responses, update_data.debate_transcript, update_data.recommendations]):
        db.update_evaluation_status(evaluation_id, update_data.status)
    return {"status": "success", "evaluation_id": evaluation_id}


@app.delete("/api/evaluations/{evaluation_id}", response_model=dict)
async def delete_evaluation_record(evaluation_id: int, db: Database = Depends(get_db)):
    evaluation = db.get_evaluation(evaluation_id)
    if not evaluation:
        raise HTTPException(status_code=404, detail="Evaluation not found")
    db.delete_evaluation(evaluation_id)
    return {"status": "success", "message": "Evaluation deleted successfully"}


@app.get("/api/statistics")
async def get_statistics(db: Database = Depends(get_db)):
    try:
        stats = db.get_statistics()
        return {
            "status": "success",
            "statistics": stats
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve statistics: {str(e)}")


@app.post("/api/evaluate/lesson")
@timing_decorator
async def evaluate_lesson(lesson_plan: dict, db: Database = Depends(get_db)):
    """
    è¯„ä¼°æ•™æ¡ˆ - ä¿®å¤è¯„åˆ†æ˜¾ç¤ºé—®é¢˜
    """
    text = lesson_plan.get("lesson_plan_text", "")
    title = lesson_plan.get("lesson_plan_title", "Untitled")
    grade_level = lesson_plan.get("grade_level", "")
    subject_area = lesson_plan.get("subject_area", "")
    
    print(f"\n{'='*60}")
    print(f"ðŸ“ EVALUATING LESSON PLAN")
    print(f"{'='*60}")
    print(f"Title: {title}")
    print(f"Grade: {grade_level}")
    print(f"Subject: {subject_area}")
    print(f"Length: {len(text)} characters")
    
    if API_MODE == "mock":
        # Mock æ•°æ® - ç¡®ä¿æ•°æ®ç»“æž„å®Œæ•´
        place_based_score = 84
        cultural_score = 82
        critical_pedagogy_score = 76
        assessment_quality_score = 74
        reflective_practice_score = 73
        overall_score = int((place_based_score + cultural_score + critical_pedagogy_score + 
                            assessment_quality_score + reflective_practice_score) / 5)
        
        print(f"ðŸ“Š Mock Scores:")
        print(f"  Place-Based: {place_based_score}")
        print(f"  Cultural: {cultural_score}")
        print(f"  Critical Pedagogy: {critical_pedagogy_score}")
        print(f"  Assessment: {assessment_quality_score}")
        print(f"  Reflective: {reflective_practice_score}")
        print(f"  Overall: {overall_score}")
        
        # ä¿®å¤: ç¡®ä¿é¡¶å±‚å’Œanalysiséƒ½æœ‰å®Œæ•´æ•°æ®
        agent_responses = [
            {
                "agent": "DeepSeek",
                "role": "Place-Based Learning Expert",
                "model": "deepseek-chat",
                "analysis": {
                    "place_based_learning": {
                        "score": place_based_score,
                        "color": score_color(place_based_score),
                        "strengths": [
                            "Strong connection to local environment and community",
                            "Engaging field-based activities that promote hands-on learning",
                            "Effective use of local case studies and examples"
                        ],
                        "areas_for_improvement": [
                            "Could include more community partnerships and guest speakers",
                            "Needs stronger connections to local iwi and cultural advisors"
                        ]
                    }
                },
                "recommendations": [
                    "Partner with local iwi for cultural guidance",
                    "Include community members in the learning process",
                    "Connect learning to specific local environmental issues"
                ]
            },
            {
                "agent": "Claude",
                "role": "Cultural Responsiveness Specialist",
                "model": "claude-sonnet-4-5",
                "analysis": {
                    "cultural_responsiveness": {
                        "score": cultural_score,
                        "color": score_color(cultural_score),
                        "strengths": [
                            "Good integration of te reo MÄori throughout the lesson",
                            "Cultural context and perspectives are included",
                            "Acknowledges MÄori concepts like kaitiakitanga"
                        ],
                        "areas_for_improvement": [
                            "Need more diverse cultural perspectives beyond MÄori",
                            "Could include more Pacific Island and other cultural viewpoints"
                        ],
                        "cultural_elements_present": [
                            "Te reo MÄori vocabulary",
                            "MÄori concepts (kaitiakitanga)",
                            "Cultural protocols and acknowledgments"
                        ]
                    }
                },
                "recommendations": [
                    "Include more diverse cultural examples and perspectives",
                    "Strengthen connections to local iwi and cultural advisors",
                    "Add cultural safety considerations"
                ]
            },
            {
                "agent": "GPT-4",
                "role": "Critical Pedagogy, Assessment & Reflective Practice Expert",
                "model": "gpt-4-turbo",
                "analysis": {
                    "critical_pedagogy": {
                        "score": critical_pedagogy_score,
                        "color": score_color(critical_pedagogy_score),
                        "strengths": [
                            "Encourages critical thinking and analysis",
                            "Student-centered approach with inquiry-based learning",
                            "Addresses power dynamics and systemic issues"
                        ],
                        "gaps": [
                            "Could include more structured reflection activities",
                            "Needs stronger focus on student voice and agency"
                        ]
                    },
                    "assessment_quality": {
                        "score": assessment_quality_score,
                        "color": score_color(assessment_quality_score),
                        "strengths": [
                            "Multiple assessment methods included",
                            "Both formative and summative assessment present",
                            "Peer assessment and self-assessment components"
                        ],
                        "gaps": [
                            "Assessment criteria could be more explicit",
                            "Need clearer rubrics for evaluation"
                        ]
                    },
                    "reflective_practice": {
                        "score": reflective_practice_score,
                        "color": score_color(reflective_practice_score),
                        "strengths": [
                            "Includes reflective journaling component",
                            "Opportunities for student self-assessment",
                            "Teacher reflection prompts included"
                        ],
                        "gaps": [
                            "Reflection could be more structured and guided",
                            "Need more explicit reflective practice frameworks"
                        ]
                    }
                },
                "recommendations": [
                    "Add structured learning journal for reflection",
                    "Include more opportunities for student-led inquiry",
                    "Strengthen connections to social justice themes",
                    "Implement detailed assessment rubric",
                    "Add more specific success criteria",
                    "Include exemplars for student reference",
                    "Add structured reflective practice framework",
                    "Include guided reflection prompts",
                    "Create reflection templates for students"
                ],
                "resources_suggested": ["assessment_rubric", "learning_journal", "peer_feedback_protocol"]
            }
        ]
        
        # åˆå¹¶æŽ¨è        ]
        
        # åˆå¹¶æŽ¨è
        recommendations = []
        for response in agent_responses:
            if "recommendations" in response.get("analysis", {}):
                recommendations.extend(response["analysis"]["recommendations"])
        recommendations = list(dict.fromkeys(recommendations))

        # ç”Ÿæˆæ”¹è¿›çš„æ•™æ¡ˆ
        fields = {
            "knowledge": "Students will understand the root causes of environmental issues and the concept of kaitiakitanga (guardianship), including both scientific and cultural perspectives.",
            "skills": "Students will be able to conduct critical analysis using WHO-WHY-WHAT framework, collect and interpret environmental data, communicate findings effectively, and collaborate with community members.",
            "values": "Students will appreciate kaitiakitanga and develop empathy for environmental issues, respect for diverse cultural perspectives, and commitment to sustainable practices.",
            "prior_knowledge": "Basic understanding of ecosystems and local waterways; some awareness of environmental issues in their community; varying levels of cultural knowledge.",
            "interests": "Many students live near affected waterways and have personal connections to local environmental issues; interests in hands-on activities and community action.",
            "challenges": "Complex scientific concepts and systemic environmental issues; varying levels of prior knowledge; potential emotional responses to environmental challenges.",
            "learning_styles": "Mix of visual, kinesthetic, and collaborative learners; need for multimodal approaches and differentiated instruction.",
            "accommodations": "Two students with dyslexia requiring printed materials in specific fonts; one ELL student needing language support; various reading levels requiring differentiated texts.",
            "key_concepts": "Critical analysis, kaitiakitanga, scientific method, power dynamics, environmental justice, cultural sustainability.",
            "focus_challenges": "Understanding abstract concepts like systemic issues; managing emotions about environmental challenges; bridging scientific and cultural knowledge systems.",
            "methods": "Inquiry-based learning, project-based learning, culturally responsive pedagogy, place-based education, critical pedagogy.",
            "strategies": "Tuakana-Teina peer support, field investigations, reflective journaling, collaborative group work, community interviews.",
            "teacher_prep": "Contact local kaumÄtua and iwi representatives; prepare water testing kits and safety equipment; create scaffold templates for critical analysis; arrange community expert visits.",
            "student_prep": "Pre-reading on local environmental issues; family interviews about waterway memories; bring photos of local water bodies; complete prior knowledge assessment.",
            "intro_details": "Karakia and mihi whakatau; video presentation on Awa Tupua concept; critical discussion using photos of local waterways; setting learning intentions and success criteria.",
            "intro_duration": "30 minutes",
            "intro_methods": "Discussion, video analysis, questioning techniques, cultural protocols",
            "main_details": "WHO-WHY-WHAT critical analysis framework; historical context of local waterways; water testing demonstration and safety procedures; cultural perspectives on water guardianship.",
            "main_duration": "45 minutes",
            "main_methods": "Direct instruction, interactive Q&A, modeling, think-pair-share",
            "activity_details": "Field investigation at local waterway; water quality data collection; group analysis of findings; community member interviews; reflective journaling.",
            "activity_duration": "90 minutes",
            "activity_methods": "Group work, hands-on investigation, data collection, interviews, reflection",
            "conclusion_details": "Group presentations of findings; whole-class synthesis of learning; reflection on cultural and scientific insights; setting personal action goals.",
            "conclusion_duration": "30 minutes",
            "conclusion_methods": "Presentation, summary discussion, reflective writing, goal setting",
            "extension_details": "Learning journal entry with specific prompts; questions for kaumÄtua follow-up; community research project; action plan development.",
            "extension_duration": "Ongoing",
            "extension_methods": "Independent research, journaling, project work, community engagement",
            "formative": "Observation during activities; journal check-ins; exit tickets; peer feedback; questioning during discussions.",
            "summative": "Group presentation with rubric; scientific report; learning journal portfolio; peer assessment; community action plan.",
            "feedback": "Weekly teacher feedback on journals; peer feedback forms; community member input; self-assessment against success criteria.",
            "materials": "Water testing kits, safety equipment, journal templates, poster boards, cultural resources, local maps, community contact information.",
            "tech_tools": "Projector for presentations, tablets for data recording, Google Classroom for submissions, data logging apps, digital cameras for documentation."
        }
        lesson_plan_text = generate_lesson_plan_from_fields(fields)

    elif API_MODE == "real":
        try:
            print("ðŸ”„ Making real LLM API calls...")
            tasks = []
            
            # DeepSeek - åœ°æ–¹å­¦ä¹ è¯„ä¼°
            tasks.append(
                asyncio.wait_for(
                    llm_client.call(
                        "deepseek",
                        f"""Evaluate this lesson plan for place-based learning quality. Return ONLY valid JSON:
{{
    "score": 85,
    "strengths": ["strength1", "strength2"],
    "areas_for_improvement": ["improvement1"],
    "recommendations": ["recommendation1"]
}}
Lesson Plan: {text[:2000]}"""
                    ),
                    timeout=30.0
                )
            )
            
            # Claude - æ–‡åŒ–å“åº”è¯„ä¼°
            tasks.append(
                asyncio.wait_for(
                    llm_client.call(
                        "claude",
                        f"""Evaluate cultural responsiveness. Return ONLY valid JSON:
{{
    "score": 80,
    "strengths": ["strength1"],
    "areas_for_improvement": ["improvement1"],
    "cultural_elements_present": ["element1"],
    "recommendations": ["recommendation1"]
}}
Lesson: {text[:2000]}"""
                    ),
                    timeout=30.0
                )
            )
            
            # GPT-4 - ç”Ÿæˆæ”¹è¿›æ•™æ¡ˆ
            tasks.append(
                asyncio.wait_for(
                    llm_client.call(
                        "chatgpt",
                        f"""Generate improved lesson plan fields. Return ONLY valid JSON with ALL these keys:
{{
    "knowledge": "text", "skills": "text", "values": "text",
    "prior_knowledge": "text", "interests": "text", "challenges": "text",
    "learning_styles": "text", "accommodations": "text",
    "key_concepts": "text", "focus_challenges": "text",
    "methods": "text", "strategies": "text",
    "teacher_prep": "text", "student_prep": "text",
    "intro_details": "text", "intro_duration": "20min", "intro_methods": "text",
    "main_details": "text", "main_duration": "40min", "main_methods": "text",
    "activity_details": "text", "activity_duration": "45min", "activity_methods": "text",
    "conclusion_details": "text", "conclusion_duration": "15min", "conclusion_methods": "text",
    "extension_details": "text", "extension_duration": "ongoing", "extension_methods": "text",
    "formative": "text", "summative": "text", "feedback": "text",
    "materials": "text", "tech_tools": "text"
}}
Original: {text[:2000]}"""
                    ),
                    timeout=45.0
                )
            )
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            print("âœ… LLM calls completed")
            
            # å¤„ç†ç»“æžœ
            ds_content = results[0] if not isinstance(results[0], Exception) else None
            cl_content = results[1] if not isinstance(results[1], Exception) else None
            cg_content = results[2] if not isinstance(results[2], Exception) else None
            
            if isinstance(results[0], Exception):
                print(f"âš ï¸ DeepSeek error: {results[0]}")
            if isinstance(results[1], Exception):
                print(f"âš ï¸ Claude error: {results[1]}")
            if isinstance(results[2], Exception):
                print(f"âš ï¸ ChatGPT error: {results[2]}")
            
            # è§£æžå“åº”
            def parse_json_response(content, default_score=70):
                if content is None:
                    return {"score": default_score, "strengths": [], "areas_for_improvement": [], "recommendations": []}
                if isinstance(content, dict):
                    return content
                try:
                    if isinstance(content, str):
                        content = content.strip()
                        if content.startswith("```json"):
                            content = content[7:]
                        if content.startswith("```"):
                            content = content[3:]
                        if content.endswith("```"):
                            content = content[:-3]
                        content = content.strip()
                        return json.loads(content)
                    return {"score": default_score, "strengths": [], "areas_for_improvement": [], "recommendations": []}
                except Exception as e:
                    print(f"âš ï¸ JSON parse error: {e}")
                    return {"score": default_score, "strengths": [], "areas_for_improvement": [], "recommendations": []}
            
            ds_analysis = parse_json_response(ds_content, 70)
            cl_analysis = parse_json_response(cl_content, 70)
            
            place_based_score = int(ds_analysis.get('score', 70))
            cultural_score = int(cl_analysis.get('score', 70))
            overall_score = int((place_based_score + cultural_score) / 2)
            
            print(f"ðŸ“Š Real Scores: Place={place_based_score}, Cultural={cultural_score}, Overall={overall_score}")
            
            # æž„å»ºagent_responses - ç¡®ä¿å®Œæ•´ç»“æž„
            agent_responses = [
                {
                    "agent": "DeepSeek",
                    "role": "Place-Based Learning Expert",
                    "score": place_based_score,
                    "color": score_color(place_based_score),
                    "analysis": {
                        "score": place_based_score,
                        "color": score_color(place_based_score),
                        "strengths": ds_analysis.get('strengths', ["Place-based analysis completed"]),
                        "areas_for_improvement": ds_analysis.get('areas_for_improvement', ["Review recommended"]),
                        "recommendations": ds_analysis.get('recommendations', ["Enhance local connections"])
                    }
                },
                {
                    "agent": "Claude",
                    "role": "Cultural Responsiveness Specialist",
                    "score": cultural_score,
                    "color": score_color(cultural_score),
                    "analysis": {
                        "score": cultural_score,
                        "color": score_color(cultural_score),
                        "strengths": cl_analysis.get('strengths', ["Cultural elements identified"]),
                        "areas_for_improvement": cl_analysis.get('areas_for_improvement', ["Cultural review needed"]),
                        "cultural_elements_present": cl_analysis.get('cultural_elements_present', ["Cultural content present"]),
                        "recommendations": cl_analysis.get('recommendations', ["Strengthen cultural connections"])
                    }
                }
            ]
            
            # åˆå¹¶æŽ¨è
            all_recommendations = []
            all_recommendations.extend(ds_analysis.get('recommendations', []))
            all_recommendations.extend(cl_analysis.get('recommendations', []))
            recommendations = list(dict.fromkeys(all_recommendations))[:7]
            
            # ç”Ÿæˆæ•™æ¡ˆ
            try:
                if cg_content:
                    fields = parse_json_response(cg_content, 0)
                    if not isinstance(fields, dict) or len(fields) < 10:
                        fields = {}
                else:
                    fields = {}
            except:
                fields = {}
            
            if not fields:
                fields = {
                    "knowledge": "Students will develop comprehensive understanding of key concepts.",
                    "skills": "Students will develop critical thinking and practical skills.",
                    "values": "Students will appreciate diverse perspectives and cultural contexts.",
                    "prior_knowledge": "Students bring varied experiences to learning.",
                    "interests": "Connecting to student interests enhances engagement.",
                    "challenges": "Addressing diverse learning needs and challenges.",
                    "learning_styles": "Accommodating diverse learning preferences.",
                    "accommodations": "Providing appropriate supports for all learners.",
                    "key_concepts": "Core concepts aligned with curriculum.",
                    "focus_challenges": "Key learning challenges to address.",
                    "methods": "Evidence-based teaching methods.",
                    "strategies": "Effective instructional strategies.",
                    "teacher_prep": "Required teacher preparations and materials.",
                    "student_prep": "Student preparations and requirements.",
                    "intro_details": "Engaging introduction to activate interest.",
                    "intro_duration": "15-20 minutes",
                    "intro_methods": "Discussion, questioning, multimedia",
                    "main_details": "Core content delivery with scaffolding.",
                    "main_duration": "35-45 minutes",
                    "main_methods": "Direct instruction, modeling, practice",
                    "activity_details": "Hands-on activities and collaboration.",
                    "activity_duration": "40-50 minutes",
                    "activity_methods": "Group work, investigations, projects",
                    "conclusion_details": "Summary and reflection on learning.",
                    "conclusion_duration": "10-15 minutes",
                    "conclusion_methods": "Discussion, reflection, assessment",
                    "extension_details": "Further learning opportunities.",
                    "extension_duration": "Ongoing",
                    "extension_methods": "Independent study, projects",
                    "formative": "Ongoing assessment and feedback.",
                    "summative": "Final assessment of outcomes.",
                    "feedback": "Regular constructive feedback.",
                    "materials": "Required teaching and learning materials.",
                    "tech_tools": "Technology tools and resources."
                }
            
            lesson_plan_text = generate_lesson_plan_from_fields(fields)
            
        except asyncio.TimeoutError:
            print("âŒ Timeout")
            raise HTTPException(status_code=504, detail="Evaluation timeout")
        except Exception as e:
            print(f"âŒ Error: {str(e)}")
            print(traceback.format_exc())
            raise HTTPException(status_code=500, detail=f"Evaluation failed: {str(e)}")
    else:
        raise HTTPException(status_code=400, detail=f"Unsupported API_MODE: {API_MODE}")

    # ä¿å­˜åˆ°æ•°æ®åº“
    try:
        eval_id = db.create_evaluation(
            lesson_plan_text=text,
            lesson_plan_title=title,
            grade_level=grade_level,
            subject_area=subject_area,
            api_mode=API_MODE
        )
        
        print(f"ðŸ’¾ Saving evaluation: eval_id={eval_id}")
        print(f"ðŸ’¾ Scores: place={place_based_score}, cultural={cultural_score}, overall={overall_score}")
        
        # ä¿å­˜è¯„åˆ†
        db.update_evaluation_scores(
            eval_id=eval_id,
            place_based_score=place_based_score,
            cultural_score=cultural_score,
            overall_score=overall_score
        )
        
        # ä¿å­˜å®Œæ•´ç»“æžœ
        db.update_evaluation_results(
            eval_id=eval_id,
            agent_responses=agent_responses,
            debate_transcript={},
            recommendations=recommendations,
            status="completed"
        )
        
        print(f"âœ… Evaluation saved successfully")
        print(f"{'='*60}\n")
        
    except Exception as e:
        print(f"âŒ Database error: {str(e)}")
        print(traceback.format_exc())

    # è¿”å›žç»“æžœ - ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ­£ç¡®
    return {
        "status": "success",
        "evaluation_id": eval_id,
        "agent_responses": agent_responses,
        "recommendations": recommendations,
        "scores": {
            "place_based_learning": place_based_score,
            "cultural_responsiveness": cultural_score,
            "critical_pedagogy": critical_pedagogy_score,
            "assessment_quality": assessment_quality_score,
            "reflective_practice": reflective_practice_score,
            "overall": overall_score
        },
        "mode": API_MODE
    }


@app.post("/api/improve-lesson")
@timing_decorator
async def improve_lesson(request: ImproveLessonRequest):
    try:
        response = await asyncio.wait_for(
            llm_client.call(
                "chatgpt",
                f"""Improve lesson plan. Return ONLY valid JSON with these keys:
knowledge, skills, values, prior_knowledge, interests, challenges,
learning_styles, accommodations, key_concepts, focus_challenges,
methods, strategies, teacher_prep, student_prep,
intro_details, intro_duration, intro_methods,
main_details, main_duration, main_methods,
activity_details, activity_duration, activity_methods,
conclusion_details, conclusion_duration, conclusion_methods,
extension_details, extension_duration, extension_methods,
formative, summative, feedback, materials, tech_tools

Recommendations: {', '.join(request.recommendations[:3])}
Original: {request.original_lesson[:1500]}"""
            ),
            timeout=60.0
        )
        
        try:
            if isinstance(response, str):
                response = response.strip()
                if response.startswith("```json"):
                    response = response[7:]
                if response.startswith("```"):
                    response = response[3:]
                if response.endswith("```"):
                    response = response[:-3]
                response = response.strip()
                fields = json.loads(response)
            else:
                fields = response
                
            if not isinstance(fields, dict):
                fields = {}
        except:
            fields = {}
        
        improved_lesson = generate_lesson_plan_from_fields(fields)
        
        return {
            "status": "success",
            "improved_lesson": improved_lesson,
            "original_title": request.lesson_title,
            "recommendations_applied": len(request.recommendations)
        }
        
    except asyncio.TimeoutError:
        raise HTTPException(status_code=504, detail="Timeout")
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed: {str(e)}")


@app.get("/api/health")
async def health_check():
    return {"status": "ok", "message": "Service is healthy"}


print("ðŸš€ Lesson Plan Evaluator API is ready to accept requests")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app", 
        host="0.0.0.0",  # å…è®¸æ‰€æœ‰ä¸»æœºè¿žæŽ¥
        port=8000, 
        reload=True,
        access_log=True  # å¯ç”¨è®¿é—®æ—¥å¿—
    )